{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More about LangChain RAG: https://learn.deeplearning.ai/courses/langchain-chat-with-your-data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "pip install transformers\n",
    "\n",
    "pip install langchain, langchain-huggingface, langchain-community\n",
    "\n",
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from langchain_huggingface import HuggingFacePipeline, ChatHuggingFace\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    "    )\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import AsyncHtmlLoader\n",
    "from langchain_community.document_transformers import BeautifulSoupTransformer\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load LLM and simple QA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Load LLM\n",
    "model_id = \"unsloth/Llama-3.2-1B-Instruct\"\n",
    "# microsoft/Phi-4-mini-instruct\n",
    "# google/gemma-3-1b-it\n",
    "# meta-llama/Llama-3.2-1B-Instruct\n",
    "# unsloth/Llama-3.2-1B-Instruct\n",
    "\n",
    "# LLM\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=model_id,\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs=dict(\n",
    "        max_new_tokens=512,\n",
    "        do_sample=False,\n",
    "        repetition_penalty=1.03,\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "# Chat\n",
    "chat = ChatHuggingFace(llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\chan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"What is SmartLab? SmartLab is a company that specializes in developing and manufacturing high-quality, innovative laboratory equipment for the scientific community. Their products are designed to make scientific research more efficient, accurate, and cost-effective.\\n\\nSmartLab's products include a wide range of laboratory instruments, such as microscopes, spectrometers, and centrifuges, as well as software solutions for data analysis and visualization. Their equipment is known for its high precision, reliability, and ease of use, making it accessible to researchers from various disciplines, including biology, chemistry, physics, and more.\\n\\nSome of the key features of SmartLab's products include:\\n\\n* High-resolution imaging and spectroscopy\\n* Advanced data analysis and visualization tools\\n* Compact and portable designs\\n* Easy-to-use interfaces and software\\n* Compatibility with a wide range of operating systems\\n\\nOverall, SmartLab is a leading provider of laboratory equipment and software solutions for the scientific community, helping researchers to advance their knowledge and discoveries.\\n\\n**Key Features:**\\n\\n* High-resolution imaging and spectroscopy\\n* Advanced data analysis and visualization tools\\n* Compact and portable designs\\n* Easy-to-use interfaces and software\\n* Compatibility with a wide range of operating systems\\n\\n**Target Audience:**\\n\\n* Researchers in various disciplines (biology, chemistry, physics, etc.)\\n* Academics and students\\n* Industry professionals (pharmaceuticals, biotechnology, etc.)\\n\\n**Industry Applications:**\\n\\n* Research and development\\n* Clinical diagnostics\\n* Pharmaceutical industry\\n* Biotechnology\\n* Food and beverage industry\\n\\n**Competitive Advantage:**\\n\\n* High-quality, innovative products\\n* Wide range of products and services\\n* Strong customer support and technical expertise\\n* Competitive pricing and value proposition\\n\\n**Company Overview:**\\n\\n* Founded in [Year]\\n* Headquartered in [Location]\\n* Global presence with a network of distributors and partners\\n* Strong online presence through e-commerce platform and social media channels\\n\\n**Revenue Model:**\\n\\n* Direct sales of products and services\\n* Licensing agreements with universities and research institutions\\n* Partnerships with industry partners and suppliers\\n\\n**Growth Strategy:**\\n\\n* Expand product offerings and services to meet growing demand\\n* Develop strategic partnerships with research institutions and industry leaders\\n* Invest in marketing and sales efforts to increase brand awareness and customer acquisition\\n\\n**Financial Projections:**\\n\\n* Revenue growth: [Percentage] per annum\\n* Net income growth: [Percentage] per annum\\n* Market share growth: [Percentage] per annum\\n\\nNote: The above information is fictional and used for demonstration purposes only. SmartLab is a real company\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"What is SmartLab?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\chan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 27 Mar 2025\\n\\nYou are a helpful assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nWhat is SmartLab?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nSmartLab is a platform that allows users to create and manage their own virtual labs, where they can conduct experiments, simulations, and research in a safe and controlled environment. It's often used in educational settings, such as schools and universities, to teach various scientific concepts and skills.\\n\\nWith SmartLab, users can create virtual labs that mimic real-world experiments, allowing students to explore and learn about different scientific principles and phenomena in a hands-on way. The platform provides a range of features, including:\\n\\n1. Virtual lab environments: Users can create and customize their own virtual labs, including setting up equipment, adding materials, and designing experiments.\\n2. Experiment design: Users can design and plan their experiments, including selecting variables, controlling conditions, and collecting data.\\n3. Data analysis: Users can collect and analyze data, using tools and visualizations to understand the results.\\n4. Collaboration: SmartLab allows users to collaborate with others, sharing their work and receiving feedback and guidance.\\n5. Virtual reality (VR) and augmented reality (AR) integration: Some versions of SmartLab offer VR and AR capabilities, allowing users to immerse themselves in virtual labs and experiments.\\n\\nSmartLab is designed to be user-friendly and accessible, making it suitable for students of all ages and skill levels. It's also a great tool for professionals in various fields, such as researchers, scientists, and educators, who can use it to teach and conduct experiments in a more engaging and interactive way.\\n\\nSome examples of what you can do with SmartLab include:\\n\\n* Conducting chemistry experiments, such as mixing chemicals, creating chemical reactions, and analyzing results\\n* Simulating biological systems, such as modeling population growth, disease spread, or climate change\\n* Exploring physics concepts, such as gravity, motion, and energy\\n* Analyzing data from various fields, such as astronomy, biology, or economics\\n\\nOverall, SmartLab is a powerful tool that can help users learn, teach, and explore complex scientific concepts in a fun and interactive way.\", additional_kwargs={}, response_metadata={}, id='run-3a1de7f7-4a70-4eef-9ce9-60d3ead2756d-0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\"system\", \"You are a helpful assistant.\"),\n",
    "    (\"human\", \"What is SmartLab?\"),\n",
    "]\n",
    "\n",
    "chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Beautiful soup\n",
    "pip install beautifulsoup4\n",
    "\n",
    "https://pypi.org/project/beautifulsoup4/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG from webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|##########| 1/1 [00:00<00:00,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "15864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load documents from webpage\n",
    "urls = [\"https://www.metropolia.fi/fi/tutkimus-kehitys-ja-innovaatiot/yhteistyoalustat/smart-lab\"]\n",
    "loader_html = AsyncHtmlLoader(urls)\n",
    "docs_html = loader_html.load()\n",
    "\n",
    "bs_transformer = BeautifulSoupTransformer()\n",
    "docs_transformed = bs_transformer.transform_documents(docs_html, tags_to_extract=[\"div\"])\n",
    "\n",
    "# Split it into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "docs_transformed_split = text_splitter.split_documents(docs_transformed)\n",
    "\n",
    "\n",
    "print(len(docs_transformed_split))\n",
    "print(len(docs_transformed[0].page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another alternative to copy the content on another website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|##########| 1/1 [00:00<00:00,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "5225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load documents from webpage\n",
    "urls = [\"https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-2-reflection/\"]\n",
    "loader_html = AsyncHtmlLoader(urls)\n",
    "docs_html = loader_html.load()\n",
    "\n",
    "bs_transformer = BeautifulSoupTransformer()\n",
    "docs_transformed = bs_transformer.transform_documents(docs_html, tags_to_extract=[\"div\"])\n",
    "\n",
    "# Split it into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "docs_transformed_split = text_splitter.split_documents(docs_transformed)\n",
    "\n",
    "\n",
    "print(len(docs_transformed_split))\n",
    "print(len(docs_transformed[0].page_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the open-source embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# load it into FAISS\n",
    "html_db = FAISS.from_documents(docs_transformed_split, embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retriever\n",
    "\n",
    "retriever_html = html_db.as_retriever()\n",
    "\n",
    "qa_web = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever_html,    \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrival QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval QA \n",
    "from time import time\n",
    "def qa_rag(qa, query):\n",
    "    print(f\"Query: {query}\\n\")\n",
    "    time_1 = time()\n",
    "    result = qa.run(query)\n",
    "    time_2 = time()\n",
    "    print(f\"Inference time: {round(time_2-time_1, 3)} sec.\")\n",
    "    print(\"\\nResult:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Who are involved in the project SmartLab?\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chan\\AppData\\Local\\Temp\\ipykernel_16752\\556439366.py:6: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa.run(query)\n",
      "C:\\Users\\chan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\chan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Inference time: 1.088 sec.\n",
      "\n",
      "Result: Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "(/sites/default/files/2021-12/sl_049_nettikoko.jpg) SmartLab-keittiö   (/sites/default/files/2021-12/sl_108_nettikoko.jpg)                (/sites/default/files/2021-12/sl_108_nettikoko.jpg) SmartLab-paneeli   (/sites/default/files/2021-12/sl_015_nettikoko.jpg)                (/sites/default/files/2021-12/sl_015_nettikoko.jpg) SmartLab sähkökaappi   (/sites/default/files/2021-12/sl_059_nettikoko.jpg)                (/sites/default/files/2021-12/sl_059_nettikoko.jpg) Valokatkaisimia SmartLabissa   (/sites/default/files/2021-12/sl_060_nettikoko.jpg)                (/sites/default/files/2021-12/sl_060_nettikoko.jpg) SmartLab valaistus Ota yhteyttä Teknologiapäällikkö Harri Hahkala p. 040 082 8636 harri.hahkala [at] metropolia.fi (harri[dot]hahkala[at]metropolia[dot]fi) Innovaatiojohtaja Anna-Stina Tähkävuori p. 040 670 8525 anna-stina.tahkavuori [at] metropolia.fi (anna-stina[dot]tahkavuori[at]metropolia[dot]fi) Yhteistyössä   (https://new.abb.com/fi)\n",
      "\n",
      "rakentajien kampus.  Myyrmäen kampus (/fi/metropoliasta/kampukset/myyrmaki) Myyrmäen kampuksella teollinen teknologia ja kansainvälinen liiketalous paiskaavat kättä.   (/fi/verkkokauppa) Verkkokauppa  (/fi/verkkokauppa) SmartLab – älykotien kehitysalusta   Etusivu (/fi)  Tutkimus-, kehitys- ja innovaatiotoiminta (/fi/tutkimus-kehitys-ja-innovaatiot)  Yhteistyöalustat (/fi/tutkimus-kehitys-ja-innovaatiot/yhteistyoalustat) Smart Lab   Myllypuron kampuksella sijaitseva SmartLab on asumista palvelevan teknologian kehittämiseen ja testaukseen suunniteltu asunto, joka toimii myös koekenttänä innovaatioprojekteissa ja opinnäytetöissä. SmartLab on Skanskan (https://www.skanska.fi/) , ABB:n (https://new.abb.com/fi) ja Metropolian yhteinen hanke. Älykotialustalla testataan ja kehitetään teknologioita, rajapintoja ja käytäntöjä, joiden avulla voidaan kehittää asumista palvelevia käyttäjäystävällisiä ratkaisuja. Ratkaisujen on tarkoitus soveltua elämänkaaren eri vaiheisiin. Laajemmin tavoitteena\n",
      "\n",
      "Tällainen tulevaisuuden koti voi olla – SmartLabissa kiihdytetään älykkään asumisen ratkaisuja (/fi/metropoliasta/ajankohtaista/uutiset/tallainen-tulevaisuuden-koti-voi-olla-smartlabissa-kiihdytetaan-alykkaan-asumisen-ratkaisuja) Skanskan, ABB:n ja Metropolian yhteinen SmartLab-alusta kiihdyttää älykkään asumisen ratkaisuja (/fi/metropoliasta/ajankohtaista/uutiset/skanskan-abbn-ja-metropolian-yhteinen-smartlab-alusta-kiihdyttaa-alykkaan-asumisen-ratkaisuja) Skanskan lehdistötiedote: Skanska ja ABB toteuttavat yhteistyössä Metropolian kanssa SmartLab-alustan älykotien kehittämiseen (https://www.skanska.fi/tietoa-skanskasta/media/uutiset/241473/Skanska-ja-ABB-toteuttavat-yhteistyossa-Metropolian-kanssa-SmartLabalustan-alykotien-kehittamiseen) Rakennuslehti 1/2020: Skanska ja ABB kehittävät älykotia yhdessä Metropolian kanssa (https://www.rakennuslehti.fi/2020/01/skanska-ja-abb-kehittavat-alykotia-yhdessa-metropolian-kanssa/)  Metropolia Ammattikorkeakoulu Käyntiosoite Myllypurontie 1,\n",
      "\n",
      "näkökulmasta erilaisia ratkaisuja, jotka edistävät hyvinvointia ja helpottavat arkielämää tulevaisuuden älykkäissä kodeissa. Ratkaisujen toivotaan olevan sellaisia, jotka palvelevat mahdollisimman monia ihmisiä iästä, taustasta tai tarpeista riippumatta. SmartLabissa olemassa olevat tekniset järjestelmät voivat tukea ratkaisujen toteuttamista mutta projektin tarkoituksena ei ole suunnitella älykotijärjestelmiä vaan tunnistaa ja edistää niiden sosiaalisia tarpeita, käyttötapauksia ja käytettävyyttä erilaisia ihmisiä palvelevalla tavalla. Ryhmän kehittämä ratkaisu on mahdollista toteuttaa käytännössä tulevaisuudessa SmartLab -alustalla. SmartLabin rakentaminen Kuvia SmartLabista   (/sites/default/files/2021-12/sl_079_nettikoko.jpg)                (/sites/default/files/2021-12/sl_079_nettikoko.jpg) Smartlab   (/sites/default/files/2021-12/sl_049_nettikoko.jpg)                (/sites/default/files/2021-12/sl_049_nettikoko.jpg) SmartLab-keittiö\n",
      "\n",
      "Question: Who are involved in the project SmartLab?\n",
      "Helpful Answer: The project SmartLab is being carried out by a team of experts from Skanska, ABB, and Metropolia.\n"
     ]
    }
   ],
   "source": [
    "query = \"Who are involved in the project SmartLab?\"\n",
    "qa_rag(qa_web, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is agentic reasoning?\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\generation\\configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\chan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\generation\\configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Inference time: 1.991 sec.\n",
      "\n",
      "Result: Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Read \"Agentic Design Patterns Part 3, Tool Use\" (https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-3-tool-use/?ref=dl-staging-website.ghost.io) Read \"Agentic Design Patterns Part 4: Planning\" (https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-4-planning/?ref=dl-staging-website.ghost.io) Read \"Agentic Design Patterns Part 5: Multi-Agent Collaboration\" (https://www.deeplearning.ai/the-batch/agentic-design-patterns-part-5-multi-agent-collaboration/?ref=dl-staging-website.ghost.io) Share Subscribe to The Batch Stay updated with weekly AI News and Insights delivered to your inbox Courses The Batch Community Careers About\n",
      "\n",
      "✨ New course! Enroll in   Vibe Coding 101 with Replit (https://bit.ly/4l8QyZ5) Explore Courses AI Newsletter The Batch Andrew's Letter Data Points ML Research Blog Community Forum Events Ambassadors Ambassador Spotlight Resources Company About Careers Contact Start Learning (https://bit.ly/3RB9T8a) Weekly Issues Andrew's Letters Data Points ML Research Business Science Culture Hardware AI Careers About Subscribe The Batch Letters Article Agentic Design Patterns Part 2, Reflection Large language models can become more effective agents by reflecting on their own behavior. Letters Technical Insights Published Mar 27, 2024 Reading time 2  min read Share Dear friends, Last week, I described four design patterns for AI agentic workflows that I believe will drive significant progress this year: Reflection, Tool Use, Planning and Multi-agent collaboration. Instead of having an LLM generate its final output directly, an agentic workflow prompts the LLM multiple times, giving it opportunities to\n",
      "\n",
      "output directly, an agentic workflow prompts the LLM multiple times, giving it opportunities to build step by step to higher-quality output. In this letter, I'd like to discuss Reflection. For a design pattern that’s relatively quick to implement, I've seen it lead to surprising performance gains. You may have had the experience of prompting ChatGPT/Claude/Gemini, receiving unsatisfactory output, delivering critical feedback to help the LLM improve its response, and then getting a better response. What if you automate the step of delivering critical feedback, so the model automatically criticizes its own output and improves its response? This is the crux of Reflection. Take the task of asking an LLM to write code. We can prompt it to generate the desired code directly to carry out some task X. After that, we can prompt it to reflect on its own output, perhaps as follows: Here’s code intended for task X: [previously generated code] Check the code carefully for correctness, style, and\n",
      "\n",
      "cases or searching the web to double-check text output. Then it can reflect on any errors it found and come up with ideas for improvement. Further, we can implement Reflection using a multi-agent framework. I've found it convenient to create two different agents, one prompted to generate good outputs and the other prompted to give constructive criticism of the first agent's output. The resulting discussion between the two agents leads to improved responses. Reflection is a relatively basic type of agentic workflow, but I've been delighted by how much it improved my applications’ results in a few cases. I hope you will try it in your own work. If you’re interested in learning more about reflection, I recommend these papers: “ Self-Refine: Iterative Refinement with Self-Feedback (https://arxiv.org/abs/2303.17651?utm_campaign=The%20Batch&utm_source=hs_email&utm_medium=email&_hsenc=p2ANqtz-9dHVnW1I1bA3sPBbsikjT165Qez3QiiAssknCERwgki818YHG7PyHOQSgg-nxKDa0BuE7B) ,” Madaan et al. (2023) “\n",
      "\n",
      "Question: What is agentic reasoning?\n",
      "Helpful Answer: Agentic reasoning refers to the ability of a system to reason and make decisions based on its own experiences, knowledge, and goals, rather than solely relying on external information or rules. It involves the use of self-awareness, autonomy, and self-regulation to guide decision-making processes. Agentic reasoning is a key aspect of agentic design patterns, as it enables systems to adapt, learn, and improve over time.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is agentic reasoning?\"\n",
    "qa_rag(qa_web, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear RAM cache\n",
    "#del pipe\n",
    "\n",
    "# Clear CUDA cache\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
